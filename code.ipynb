{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "Latex Macros\n",
    "-->\n",
    "$$\n",
    "\\newcommand{\\bar}{\\,|\\,}\n",
    "\\newcommand{\\Xs}{\\mathcal{X}}\n",
    "\\newcommand{\\Ys}{\\mathcal{Y}}\n",
    "\\newcommand{\\y}{\\mathbf{y}}\n",
    "\\newcommand{\\weights}{\\mathbf{w}}\n",
    "\\newcommand{\\balpha}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\bbeta}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\aligns}{\\mathbf{a}}\n",
    "\\newcommand{\\align}{a}\n",
    "\\newcommand{\\source}{\\mathbf{s}}\n",
    "\\newcommand{\\target}{\\mathbf{t}}\n",
    "\\newcommand{\\ssource}{s}\n",
    "\\newcommand{\\starget}{t}\n",
    "\\newcommand{\\repr}{\\mathbf{f}}\n",
    "\\newcommand{\\repry}{\\mathbf{g}}\n",
    "\\newcommand{\\x}{\\mathbf{x}}\n",
    "\\newcommand{\\prob}{p}\n",
    "\\newcommand{\\vocab}{V}\n",
    "\\newcommand{\\params}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\param}{\\theta}\n",
    "\\DeclareMathOperator{\\perplexity}{PP}\n",
    "\\DeclareMathOperator{\\argmax}{argmax}\n",
    "\\DeclareMathOperator{\\argmin}{argmin}\n",
    "\\newcommand{\\train}{\\mathcal{D}}\n",
    "\\newcommand{\\counts}[2]{\\#_{#1}(#2) }\n",
    "\\newcommand{\\length}[1]{\\text{length}(#1) }\n",
    "\\newcommand{\\indi}{\\mathbb{I}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the last assignment, you will apply deep learning methods to solve a particular story understanding problem. Automatic understanding of stories is an important task in natural language understanding [[1]](http://anthology.aclweb.org/D/D13/D13-1020.pdf). Specifically, you will develop a model that given a sequence of sentences learns to sort these sentence in order to yield a coherent story [[2]](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/short-commonsense-stories.pdf). This sounds (and to an extent is) trivial for humans, however it is quite a difficult task for machines as it involves commonsense knowledge and temporal understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "You are given a dataset of 45502 instances, each consisting of 5 sentences. Your system needs to ouput a sequence of numbers which represent the predicted order of these sentences. For example, given a story:\n",
    "\n",
    "    He went to the store.\n",
    "    He found a lamp he liked.\n",
    "    He bought the lamp.\n",
    "    Jan decided to get a new lamp.\n",
    "    Jan's lamp broke.\n",
    "\n",
    "your system needs to provide an answer in the following form:\n",
    "\n",
    "    2\t3\t4\t1\t0\n",
    "\n",
    "where the numbers correspond to the zero-based index of each sentence in the correctly ordered story. So \"`2`\" for \"`He went to the store.`\" means that this sentence should come 3rd in the correctly ordered target story. In this particular example, this order of indices corresponds to the following target story:\n",
    "\n",
    "    Jan's lamp broke.\n",
    "    Jan decided to get a new lamp.\n",
    "    He went to the store.\n",
    "    He found a lamp he liked.\n",
    "    He bought the lamp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "To develop your model(s), we provide a training and a development datasets. The test dataset will be held out, and we will use it to evaluate your models. The test set is coming from the same task distribution, and you don't need to expect drastic changes in it.\n",
    "\n",
    "You will use [TensorFlow](https://www.tensorflow.org/) to build a deep learning model for the task. We provide a very crude system which solves the task with a low accuracy, and a set of additional functions you will have to use to save and load the model you create so that we can run it.\n",
    "\n",
    "As we have to run the notebooks of each submission, and as deep learning models take long time to train, your notebook **NEEDS** to conform to the following requirements:\n",
    "* You **NEED** to run your parameter optimisation offline, and provide your final model saved by using the provided function\n",
    "* The maximum size of a zip file you can upload to moodle is 160MB. We will **NOT** allow submissions larger than that.\n",
    "* We do not have time to train your models from scratch! You **NEED** to provide the full code you used for the training of your model, but by all means you **CANNOT** call the training method in the notebook you will send to us.\n",
    "* We will run these notebooks automatically. If your notebook runs the training procedure, in addition to loading the model, and we need to edit your code to stop the training, you will be penalised with **-20 points**.\n",
    "* If you do not provide a pretrained model, and rely on training your model on our machines, you will get **0 points**.\n",
    "* Your submissions will be tested on the stat-nlp-book Docker image to ensure that it does not have any dependencies outside of those that we provide. If your submission fails to adhere to this requirement, you will get **0 points**.\n",
    "\n",
    "Running time and memory issues:\n",
    "* We have tested a possible solution on a mid-2014 MacBook Pro, and a few epochs of the model run in less than 3min. Thus it is possible to train a model on the data in reasonable time. However, be aware that you will need to run these models many times over, for a larger number of epochs (more elaborate models, trained on much larger datasets can train for weeks! However, this shouldn't be the case here.). If you find training times too long for your development cycle you can reduce the training set size. Once you have found a good solution you can increase the size again. Caveat: model parameters tuned on a smaller dataset may not be optimal for a larger training set.\n",
    "* In addition to this, as your submission is capped by size, feel free to experiment with different model sizes, numeric values of different precisions, filtering the vocabulary size, downscaling some vectors, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "A non-exhaustive list of things you might want to give a try:\n",
    "- better tokenization\n",
    "- experiment with pre-trained word representations such as [word2vec](https://code.google.com/archive/p/word2vec/), or [GloVe](http://nlp.stanford.edu/projects/glove/). Be aware that these representations might take a lot of parameters in your model. Be sure you use only the words you expect in the training/dev set and account for OOV words. When saving the model parameters, pre-rained word embeddings can simply be used in the word embedding matrix of your model. As said, make sure that this word embedding matrix does not contain all of word2vec or GloVe. Your submission is limited, and we will not allow uploading nor using the whole representations set (up to 3GB!)\n",
    "- reduced sizes of word representations\n",
    "- bucketing and batching (our implementation is deliberately not a good one!)\n",
    "  - make sure to draw random batches from the data! (we do not provide this in our code!)\n",
    "- better models:\n",
    "  - stacked RNNs (see tf.contrib.rnn.MultiRNNCell)\n",
    "  - bi-directional RNNs\n",
    "  - attention\n",
    "  - word-by-word attention\n",
    "  - conditional encoding\n",
    "  - get model inspirations from papers on [nlp.stanford.edu/projects/snli/](nlp.stanford.edu/projects/snli/)\n",
    "  - sequence-to-sequence encoder-decode architecture for producing the right ordering\n",
    "- better training procedure:\n",
    "  - different training algorithms\n",
    "  - dropout on the input and output embeddings (see tf.nn.dropout)\n",
    "  - L2 regularization (see tf.nn.l2_loss)\n",
    "  - gradient clipping (see tf.clip_by_value or tf.clip_by_norm)\n",
    "- model selection:\n",
    "  - early stopping\n",
    "- hyper-parameter optimization (e.g. random search or grid search (expensive!))\n",
    "    - initial learning rate\n",
    "    - dropout probability\n",
    "    - input and output size\n",
    "    - L2 regularization\n",
    "    - gradient clipping value\n",
    "    - batch size\n",
    "    - ...\n",
    "- post-processing\n",
    "  - for incorporating consistency constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Instructions\n",
    "It is important that this file is placed in the **correct directory**. It will not run otherwise. The correct directory is\n",
    "\n",
    "    DIRECTORY_OF_YOUR_BOOK/assignments/2017/assignment3/problem/group_X/\n",
    "    \n",
    "where `DIRECTORY_OF_YOUR_BOOK` is a placeholder for the directory you downloaded the book to, and in `X` in `group_X` contains the number of your group.\n",
    "\n",
    "After you placed it there, **rename the notebook file** to `group_X.ipynb`.\n",
    "\n",
    "The notebook is pre-set to save models in\n",
    "\n",
    "    DIRECTORY_OF_YOUR_BOOK/assignments/2017/assignment3/problem/group_X/model/\n",
    "\n",
    "Be sure not to tinker with that directory - we expect your submission to contain a `model` subdirectory with a single saved model! \n",
    "The saving procedure might overwrite the latest save, or not. Make sure you understand what it does, and upload only a single model! (for more details check tf.train.Saver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Instructions\n",
    "This notebook will be used by you to provide your solution, and by us to both assess your solution and enter your marks. It contains three types of sections:\n",
    "\n",
    "1. **Setup** Sections: these sections set up code and resources for assessment. **Do not edit, move nor copy these cells**.\n",
    "2. **Assessment** Sections: these sections are used for both evaluating the output of your code, and for markers to enter their marks. **Do not edit, move, nor copy these cells**.\n",
    "3. **Task** Sections: these sections require your solutions. They may contain stub code, and you are expected to edit this code. For free text answers simply edit the markdown field.  \n",
    "\n",
    "**If you edit, move or copy any of the setup, assessments and mark cells, you will be penalised with -20 points**.\n",
    "\n",
    "Note that you are free to **create additional notebook cells** within a task section. \n",
    "\n",
    "Please **do not share** this assignment nor the dataset publicly, by uploading it online, emailing it to friends etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "To submit your solution:\n",
    "\n",
    "* Make sure that your solution is fully contained in this notebook. Make sure you do not use any additional files other than your saved model.\n",
    "* Make sure that your solution runs linearly from start to end (no execution hops). We will run your notebook in that order.\n",
    "* **Before you submit, make sure your submission is tested on the stat-nlp-book Docker setup to ensure that it does not have any dependencies outside of those that we provide. If your submission fails to adhere to this requirement, you will get 0 points**.\n",
    "* **If running your notebook produces a trivially fixable error that we spot, we will correct it and penalise you with -20 points. Otherwise you will get 0 points for that solution.**\n",
    "* **Rename this notebook to your `group_X`** (where `X` is the number of your group), and adhere to the directory structure requirements, if you have not already done so. ** Failure to do so will result in -1 point.**\n",
    "* Download the notebook in Jupyter via *File -> Download as -> Notebook (.ipynb)*.\n",
    "* Your submission should be a zip file containing the `group_X` directory, containing `group_X.ipynb` notebook, and the `model` directory with the saved model\n",
    "* Upload that file to the Moodle submission site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 1</font>: Load Libraries\n",
    "This cell loads libraries important for evaluation and assessment of your model. **Do not change, move or copy it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:04:56.249298",
     "start_time": "2016-12-20T12:04:54.376398"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "#! SETUP 1 - DO NOT CHANGE, MOVE NOR COPY\n",
    "import sys, os\n",
    "_snlp_book_dir = \"../../../../../\"\n",
    "sys.path.append(_snlp_book_dir)\n",
    "# docker image contains tensorflow 0.10.0rc0. We will support execution of only that version!\n",
    "import statnlpbook.nn as nn\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 2</font>: Load Training Data\n",
    "\n",
    "This cell loads the training data. **Do not edit the next cell, nor copy/duplicate it**. Instead refer to the variables in your own code, and slice and dice them as you see fit (but do not change their values). \n",
    "For example, no one stops you from introducing, in the corresponding task section, `my_train` and `my_dev` variables that split the data into different folds.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:04:57.110195",
     "start_time": "2016-12-20T12:04:56.251082"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#! SETUP 2 - DO NOT CHANGE, MOVE NOR COPY\n",
    "data_path = _snlp_book_dir + \"data/nn/\"\n",
    "data_train = nn.load_corpus(data_path + \"train.tsv\")\n",
    "data_dev = nn.load_corpus(data_path + \"dev.tsv\")\n",
    "assert(len(data_train) == 45502)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structures\n",
    "\n",
    "Notice that the data is loaded from tab-separated files. The files are easy to read, and we provide the loading functions that load it into a simple data structure. Feel free to check details of the loading.\n",
    "\n",
    "The data structure at hand is an array of dictionaries, each containing a `story` and the `order` entry. `story` is a list of strings, and `order` is a list of integer indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:04:57.134033",
     "start_time": "2016-12-20T12:04:57.115270"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'order': [3, 2, 1, 0, 4],\n",
       " 'story': ['His parents understood and decided to make a change.',\n",
       "  'The doctors told his parents it was unhealthy.',\n",
       "  'Dan was overweight as well.',\n",
       "  \"Dan's parents were overweight.\",\n",
       "  'They got themselves and Dan on a diet.']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 1</font>: Model implementation\n",
    "\n",
    "Your primary task in this assignment is to implement a model that produces the right order of the sentences in the dataset.\n",
    "\n",
    "### Preprocessing pipeline\n",
    "\n",
    "First, we construct a preprocessing pipeline, in our case `pipeline` function which takes care of:\n",
    "- out-of-vocabulary words\n",
    "- building a vocabulary (on the train set), and applying the same unaltered vocabulary on other sets (dev and test)\n",
    "- making sure that the length of input is the same for the train and dev/test sets (for fixed-sized models)\n",
    "\n",
    "You are free (and encouraged!) to do your own input processing function. Should you experiment with recurrent neural networks, you will find that you will need to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='RED'><strong>TOKENIZATION</strong></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class MacIntyreContractions:\n",
    "    \"\"\"\n",
    "    List of contractions adapted from Robert MacIntyre's tokenizer.\n",
    "    \"\"\"\n",
    "    CONTRACTIONS2 = [r\"(?i)\\b(d)(?#X)('ye)\\b\",\n",
    "                     # r\"(?i)\\b(gim)(?#X)(me)\\b\",\n",
    "                     # r\"(?i)\\b(gon)(?#X)(na)\\b\",\n",
    "                     # r\"(?i)\\b(can)(?#X)(not)\\b\",\n",
    "                     # r\"(?i)\\b(got)(?#X)(ta)\\b\",\n",
    "                     # r\"(?i)\\b(lem)(?#X)(me)\\b\",\n",
    "                     r\"(?i)\\b(mor)(?#X)('n)\\b\"]\n",
    "    CONTRACTIONS3 = [r\"(?i) ('t)(?#X)(is)\\b\", r\"(?i) ('t)(?#X)(was)\\b\"]\n",
    "    CONTRACTIONS4 = [r\"(?i)\\b(whad)(dd)(ya)\\b\",\n",
    "                     r\"(?i)\\b(wha)(t)(cha)\\b\"]\n",
    "\n",
    "class TreebankWordTokenizer():\n",
    "\n",
    "    #starting quotes\n",
    "    STARTING_QUOTES = [\n",
    "        (re.compile(r'^\\\"'), r'``'),\n",
    "        (re.compile(r'(``)'), r' \\1 '),\n",
    "        (re.compile(r'([ (\\[{<])\"'), r'\\1 `` '),\n",
    "    ]\n",
    "\n",
    "    #punctuation\n",
    "    PUNCTUATION = [\n",
    "        (re.compile(r'([:,])([^\\d])'), r' \\1 \\2'),\n",
    "        (re.compile(r'([:,])$'), r' \\1 '),\n",
    "        (re.compile(r'\\.\\.\\.'), r' ... '),\n",
    "        (re.compile(r'[;@#$%&]'), r' \\g<0> '),\n",
    "        (re.compile(r'([^\\.])(\\.)([\\]\\)}>\"\\']*)\\s*$'), r'\\1 \\2\\3 '), # Handles the final period.\n",
    "        (re.compile(r'[?!]'), r' \\g<0> '),\n",
    "\n",
    "        (re.compile(r\"([^'])' \"), r\"\\1 ' \"),\n",
    "    ]\n",
    "    TIME = [(re.compile(r'([0-9]*[0-9])*:[0-5][0-9]*(a|p|A|P)(m|M)'), r'\\1 \\2\\3')]\n",
    "    # Pads parentheses\n",
    "    PARENS_BRACKETS = (re.compile(r'[\\]\\[\\(\\)\\{\\}\\<\\>]'), r' \\g<0> ')\n",
    "\n",
    "    # Optionally: Convert parentheses, brackets and converts them to PTB symbols.\n",
    "    CONVERT_PARENTHESES = [\n",
    "        (re.compile(r'\\('), '-LRB-'), (re.compile(r'\\)'), '-RRB-'),\n",
    "        (re.compile(r'\\['), '-LSB-'), (re.compile(r'\\]'), '-RSB-'),\n",
    "        (re.compile(r'\\{'), '-LCB-'), (re.compile(r'\\}'), '-RCB-')\n",
    "    ]\n",
    "\n",
    "    DOUBLE_DASHES = (re.compile(r'--'), r' -- ')\n",
    "\n",
    "    #ending quotes\n",
    "    ENDING_QUOTES = [\n",
    "        (re.compile(r'\"'), \" '' \"),\n",
    "        (re.compile(r'(\\S)(\\'\\')'), r'\\1 \\2 '),\n",
    "        (re.compile(r\"([^' ])('[sS]|'[mM]|'[dD]|') \"), r\"\\1 \\2 \"),\n",
    "        (re.compile(r\"([^' ])('ll|'LL|'re|'RE|'ve|'VE|n't|N'T) \"), r\"\\1 \\2 \"),\n",
    "    ]\n",
    "\n",
    "    # List of contractions adapted from Robert MacIntyre's tokenizer.\n",
    "    _contractions = MacIntyreContractions()\n",
    "    CONTRACTIONS2 = list(map(re.compile, _contractions.CONTRACTIONS2))\n",
    "    CONTRACTIONS3 = list(map(re.compile, _contractions.CONTRACTIONS3))\n",
    "\n",
    "    def tokenize(self, text, convert_parentheses=False, return_str=False):\n",
    "        for regexp, substitution in self.STARTING_QUOTES:\n",
    "            text = regexp.sub(substitution, text)\n",
    "\n",
    "        for regexp, substitution in self.PUNCTUATION:\n",
    "            text = regexp.sub(substitution, text)\n",
    "        for regexp, subtitution in self.TIME:\n",
    "            text = regexp.sub(subtitution,text)\n",
    "            \n",
    "        # Handles parentheses.\n",
    "        regexp, substitution = self.PARENS_BRACKETS\n",
    "        text = regexp.sub(substitution, text)\n",
    "        # Optionally convert parentheses\n",
    "        if convert_parentheses:\n",
    "            for regexp, substitution in self.CONVERT_PARENTHESES:\n",
    "                text = regexp.sub(substitution, text)\n",
    "\n",
    "        # Handles double dash.\n",
    "        regexp, substitution = self.DOUBLE_DASHES\n",
    "        text = regexp.sub(substitution, text)\n",
    "\n",
    "        #add extra space to make things easier\n",
    "        text = \" \" + text + \" \"\n",
    "\n",
    "        for regexp, substitution in self.ENDING_QUOTES:\n",
    "            text = regexp.sub(substitution, text)\n",
    "\n",
    "        for regexp in self.CONTRACTIONS2:\n",
    "            text = regexp.sub(r' \\1 \\2 ', text)\n",
    "        for regexp in self.CONTRACTIONS3:\n",
    "            text = regexp.sub(r' \\1 \\2 ', text)\n",
    "\n",
    "        # We are not using CONTRACTIONS4 since\n",
    "        # they are also commented out in the SED scripts\n",
    "        # for regexp in self._contractions.CONTRACTIONS4:\n",
    "        #     text = regexp.sub(r' \\1 \\2 \\3 ', text)\n",
    "\n",
    "        return text if return_str else text.split()\n",
    "\n",
    "\n",
    "    def span_tokenize(self, text):\n",
    "\n",
    "        raw_tokens = self.tokenize(text)\n",
    "\n",
    "        # Convert converted quotes back to original double quotes\n",
    "        # Do this only if original text contains double quote(s)\n",
    "        if '\"' in text:\n",
    "            # Find double quotes and converted quotes\n",
    "            matched = [m.group() for m in re.finditer(r'[(``)(\\'\\')(\")]+', text)]\n",
    "            \n",
    "            # Replace converted quotes back to double quotes\n",
    "            tokens = [matched.pop(0) if tok in ['\"', \"``\", \"''\"] else tok for tok in raw_tokens]\n",
    "        else:\n",
    "            tokens = raw_tokens\n",
    "\n",
    "        return align_tokens(tokens, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= \"red\"><strong>PIPELINE</strong></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "_treebank_word_tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "\n",
    "def tokenize(sent):\n",
    "    return [token for token in _treebank_word_tokenizer.tokenize(sent)]\n",
    "\n",
    "\n",
    "\n",
    "#############################\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "\n",
    "# fname = \"glove6B/glove.6B.100d.txt\"\n",
    "fname = \"./model/embeddings.txt\"\n",
    "num_dim = 300\n",
    "\n",
    "with open(fname) as f:\n",
    "    content = f.readlines()\n",
    "    line = [x.strip() for x in content] \n",
    "\n",
    "    word_embeddings = collections.defaultdict(lambda: collections.defaultdict(float))\n",
    "    word_embeddings_matrix = []\n",
    "\n",
    "    word_embeddings['<PAD>']['id'] = len(word_embeddings)\n",
    "    word_embeddings['<PAD>']['embedding'] = [random.uniform(0,0) for i in range(num_dim)]\n",
    "    word_embeddings_matrix.append(  word_embeddings['<PAD>']['embedding']  )\n",
    "\n",
    "    word_embeddings['<OOV>']['id'] = len(word_embeddings)\n",
    "    word_embeddings['<OOV>']['embedding'] = [random.uniform(-1,1) for i in range(num_dim)]\n",
    "    word_embeddings_matrix.append(  word_embeddings['<OOV>']['embedding']  )\n",
    "\n",
    "    for l in line:\n",
    "        items = l.split(' ')\n",
    "        word = items[0]\n",
    "        word_embeddings[word]['id'] = len(word_embeddings)\n",
    "        word_embeddings[word]['embedding'] = [float(x) for x in items[1:]]\n",
    "        word_embeddings_matrix.append(  word_embeddings[word]['embedding']  )\n",
    "\n",
    "    word_embeddings_matrix = np.array(word_embeddings_matrix)\n",
    "\n",
    "    # print (\"word_embeddings_matrix len: \", len(word_embeddings_matrix))\n",
    "    # print (\"word_embeddings_matrix shape: \", word_embeddings_matrix.shape)\n",
    "    # print (word_embeddings_matrix[0:1])\n",
    "    # print (word_embeddings['unk'])\n",
    "###############################\n",
    "\n",
    "def pipeline(data, vocab=None, max_sent_len_=None):\n",
    "    is_ext_vocab = True\n",
    "    if vocab is None:\n",
    "        is_ext_vocab = False\n",
    "        vocab = {'<PAD>': 0, '<OOV>': 1}\n",
    "\n",
    "    max_sent_len = -1\n",
    "    data_sentences = []\n",
    "    data_orders = []\n",
    "    for instance in data:\n",
    "        sents = []\n",
    "        for sentence in instance['story']:\n",
    "            sent = []\n",
    "            tokenized =tokenize(sentence)\n",
    "            for token in tokenized:\n",
    "                token = token.lower()\n",
    "                if token in word_embeddings:\n",
    "                    vocab[token] = len(vocab)\n",
    "                if token not in word_embeddings:\n",
    "                    token_vector = word_embeddings['<OOV>']['id']\n",
    "                else:\n",
    "                    token_vector = word_embeddings[token]['id']\n",
    "                sent.append(token_vector)\n",
    "            if len(sent) > max_sent_len:\n",
    "                max_sent_len = len(sent)\n",
    "            sents.append(sent)\n",
    "        data_sentences.append(sents)\n",
    "        data_orders.append(instance['order'])\n",
    "\n",
    "    if max_sent_len_ is not None:\n",
    "        max_sent_len = max_sent_len_\n",
    "    \n",
    "    data_len = len(data_sentences)\n",
    "    out_sentences = np.full([data_len, 5, max_sent_len], word_embeddings['<PAD>']['id'], dtype=np.int32)\n",
    "    global out \n",
    "    out = out_sentences[:]\n",
    "    \n",
    "    print ('max sent len is: ', max_sent_len)\n",
    "    \n",
    "    for i, elem in enumerate(data_sentences):\n",
    "        for j, sent in enumerate(elem):\n",
    "            if len(sent) > max_sent_len:\n",
    "                print (len(sent),\" is bigger than max len sent: \", max_sent_len)\n",
    "                out_sentences[i, j, 0:max_sent_len] = sent[0:max_sent_len]\n",
    "            else:\n",
    "                out_sentences[i, j, 0:len(sent)] = sent[0:len(sent)]\n",
    "\n",
    "    out_orders = np.array(data_orders, dtype=np.int32)\n",
    "\n",
    "    min_after_dequeue = 10000\n",
    "    _batch_size = 128\n",
    "    capacity = min_after_dequeue + 3 * _batch_size\n",
    "    out_sentences_batch, out_orders_batch = tf.train.shuffle_batch(\n",
    "          [out_sentences, out_orders], batch_size=_batch_size, capacity=capacity,\n",
    "          min_after_dequeue=min_after_dequeue)\n",
    "\n",
    "    \n",
    "    return out_sentences, out_orders, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:04:59.842961",
     "start_time": "2016-12-20T12:04:57.136946"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sent len is:  21\n"
     ]
    }
   ],
   "source": [
    "# convert train set to integer IDs\n",
    "train_stories, train_orders, vocab = pipeline(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to make sure that the `pipeline` function returns the necessary data for your computational graph feed - the required inputs in this case, as we will call this function to process your dev and test data. If you do not make sure that the same pipeline applied to the train set is applied to other datasets, your model may not work with that data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:04:59.925263",
     "start_time": "2016-12-20T12:04:59.844598"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sent len is:  21\n"
     ]
    }
   ],
   "source": [
    "# get the length of the longest sentence\n",
    "max_sent_len = train_stories.shape[2]\n",
    "\n",
    "# convert dev set to integer IDs, based on the train vocabulary and max_sent_len\n",
    "dev_stories, dev_orders, _ = pipeline(data_dev, vocab, max_sent_len_=max_sent_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can take a look at the result of the `pipeline` with the `show_data_instance` function to make sure that your data loaded correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:04:59.954655",
     "start_time": "2016-12-20T12:04:59.926701"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " Story:\n",
      "  <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>\n",
      "  <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> rhinestones <OOV>\n",
      "  rhinestones <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>\n",
      "  <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>\n",
      "  <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>\n",
      " Order:\n",
      "  [1 4 0 2 3]\n",
      "\n",
      "Desired story:\n",
      "  rhinestones <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>\n",
      "  <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>\n",
      "  <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>\n",
      "  <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>\n",
      "  <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> rhinestones <OOV>\n"
     ]
    }
   ],
   "source": [
    "nn.show_data_instance(dev_stories, dev_orders, vocab, 1870)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "The model we provide is a rudimentary, non-optimised model that essentially represents every word in a sentence with a fixed vector, sums these vectors up (per sentence) and puts a softmax at the end which aims to guess the order of sentences independently.\n",
    "\n",
    "First we define the model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:04:59.966529",
     "start_time": "2016-12-20T12:04:59.956638"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "word_vector_matrix = []\n",
    "word_vector_matrix = word_embeddings_matrix\n",
    "### MODEL PARAMETERS ###\n",
    "target_size = 5\n",
    "vocab_size = word_vector_matrix.shape[0]\n",
    "input_size = word_vector_matrix.shape[1]\n",
    "output_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then we define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red' ><strong>LSTM SENTENCE WISE</strong></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib import rnn\n",
    "learning_rate = 0.01\n",
    "num_hidden = 128\n",
    "num_features = 64\n",
    "timesteps = max_sent_len\n",
    "lstm_output_size = 64\n",
    "\n",
    "class BasicRNN():\n",
    "    def __init__(self,num_hidden, num_features, timesteps ):\n",
    "        self.num_hidden = num_hidden \n",
    "        self.num_features = num_features\n",
    "        self.timesteps = timesteps\n",
    "\n",
    "\n",
    "        self.weights = {\n",
    "            'out': tf.Variable(tf.random_normal([self.num_hidden, self.num_features]))\n",
    "        }\n",
    "        self.biases = {\n",
    "            'out': tf.Variable(tf.random_normal([self.num_features]))\n",
    "        }\n",
    "\n",
    "    def lstm_cell(self):\n",
    "          return rnn.BasicLSTMCell(self.num_hidden, forget_bias=1.0)\n",
    "\n",
    "    def buildRNN(self, x):\n",
    "        # Forward direction cell\n",
    "\n",
    "        rnn_cell = rnn.MultiRNNCell([self.lstm_cell() for _ in range(4)])\n",
    "        #x = tf.unstack(x, self.timesteps, 1) \n",
    "        # x = timesteps x batch_size x input_size\n",
    "        outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "        return tf.matmul(outputs[-1], self.weights['out']) + self.biases['out']\n",
    "\n",
    "    def buildBidirectionalRNN (self, x):\n",
    "        # Forward direction cell\n",
    "        lstm_fw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "        # Backward direction cell\n",
    "        lstm_bw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "        # Get lstm cell output\n",
    "        try:\n",
    "            outputs, _, _ = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
    "                                                  dtype=tf.float32)\n",
    "        except Exception: # Old TensorFlow version only returns outputs not states\n",
    "            outputs = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
    "                                            dtype=tf.float32)\n",
    "        outs = []\n",
    "        for output in outputs:\n",
    "             outs.append( tf.matmul(output, self.bi_weights['out']) + self.biases['out'])\n",
    "        return outs\n",
    "        \n",
    "    def buildDynaimcRNN(self, x, batch_size):\n",
    "        \n",
    "        lstm_cell = tf.contrib.rnn.BasicLSTMCell(self.num_hidden)\n",
    "        outputs, states = tf.contrib.rnn.static_rnn(lstm_cell, x, dtype=tf.float32,\n",
    "                                sequence_length=self.seqlen)\n",
    "#         outputs = tf.stack(outputs)\n",
    "#         outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "#         # Hack to build the indexing and retrieve the right output.\n",
    "#         batch_size = tf.shape(outputs)[0]\n",
    "#         # Start indices for each sample\n",
    "#         index = tf.range(0, batch_size) * self.timesteps + (self.seqlen - 1)\n",
    "#         # Indexing\n",
    "#         outputs = tf.gather(tf.reshape(outputs, [-1, self.num_hidden]), index)\n",
    "        outputs = tf.reshape(tf.stack(outputs), [-1, lstm_cell.output_size])\n",
    "#         num_partitions = 2\n",
    "#         res_out = tf.dynamic_partition(outputs, self.partitions, num_partitions)\n",
    "        # Linear activation, using outputs computed above\n",
    "        return tf.matmul(outputs, self.weights['out']) + self.biases['out']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:05:00.995336",
     "start_time": "2016-12-20T12:04:59.968153"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "beta = 0.1\n",
    "\n",
    "### MODEL ###\n",
    "tf.reset_default_graph()\n",
    "tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "## PLACEHOLDERS\n",
    "story = tf.placeholder(tf.int64, [None, None, None], \"story\")        # [batch_size x 5 x max_length]\n",
    "order = tf.placeholder(tf.int64, [None, None], \"order\")              # [batch_size x 5]\n",
    "\n",
    "batch_size = tf.shape(story)[0]\n",
    "\n",
    "sentences = [tf.reshape(x, [batch_size, -1]) for x in tf.split(axis=1, num_or_size_splits=5, value=story)]  # 5 times [batch_size x max_length]\n",
    "\n",
    "# Word embeddings\n",
    "initializer = tf.constant_initializer(word_vector_matrix)\n",
    "embeddings = tf.get_variable(\"W\", [vocab_size, input_size], initializer=initializer)\n",
    "\n",
    "sentences_embedded = [tf.nn.embedding_lookup(embeddings, sentence)   # 5 * [batch_size x max_seq_length x input_size]\n",
    "                      for sentence in sentences]\n",
    "\n",
    "basicRNN = BasicRNN(num_hidden, num_features, timesteps )\n",
    "\n",
    "# x [batch_size*5, input_size]\n",
    "\n",
    "to_single_sentence = tf.concat(sentences_embedded , axis = 0)\n",
    "\n",
    "x =  tf.unstack(to_single_sentence, timesteps, 1)\n",
    "\n",
    "\n",
    "# lstmOutput  [batch_size*5, output_size]\n",
    "lstmOutput = basicRNN.buildRNN( x )\n",
    "\n",
    "# separate lstmOutput 5x[batch_size, output_size]\n",
    "hs = tf.reshape(lstmOutput,[5, -1, lstm_output_size] )\n",
    "hs_transpose = tf.transpose(hs, [1,0,2])\n",
    "\n",
    "hs_reshape = tf.reshape(hs_transpose, [-1, 5*lstm_output_size]) #[batch_size, 5*output]\n",
    "\n",
    "logits_flat = tf.contrib.layers.linear(hs_reshape, 5 * target_size)    # [batch_size x 5*target_size]\n",
    "logits = tf.reshape(logits_flat, [-1, 5, target_size])        # [batch_size x 5 x target_size]\n",
    "\n",
    "# loss + regularization\n",
    "regularizer = tf.nn.l2_loss(embeddings)\n",
    "loss = tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=order))\n",
    "loss = tf.reduce_mean(loss + beta * regularizer)\n",
    "\n",
    "# prediction function\n",
    "unpacked_logits = [tensor for tensor in tf.unstack(logits, axis=1)]\n",
    "softmaxes = [tf.nn.softmax(tensor) for tensor in unpacked_logits]\n",
    "softmaxed_logits = tf.stack(softmaxes, axis=1)\n",
    "predict = tf.arg_max(softmaxed_logits, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sent2vec codes\n",
    "# a = tf.reshape(lstmOutput, [5,-1,64])\n",
    "# sentence_to_vec = tf.unstack(a, 5, 0)\n",
    "\n",
    "# # 5 x [batch x output_size]\n",
    "# sent_lstmOutput = basicRNN.buildBidirectionalRNN( sentence_to_vec )\n",
    "\n",
    "# hs_reshape = tf.concat(sent_lstmOutput, axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We built our model, together with the loss and the prediction function, all we are left with now is to build an optimiser on the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:05:01.184409",
     "start_time": "2016-12-20T12:05:00.997016"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#opt_op = tf.train.AdamOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training \n",
    "\n",
    "We defined the preprocessing pipeline, set the model up, so we can finally train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:05:54.615600",
     "start_time": "2016-12-20T12:05:01.186008"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 25\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.initialize_all_variables())\n",
    "#     n = train_stories.shape[0]\n",
    "\n",
    "#     for epoch in range(5):\n",
    "#         print('----- Epoch', epoch, '-----')\n",
    "#         total_loss = 0\n",
    "#         for i in range(n // BATCH_SIZE):\n",
    "#             inst_story = train_stories[i * BATCH_SIZE: (i + 1) * BATCH_SIZE]\n",
    "#             inst_order = train_orders[i * BATCH_SIZE: (i + 1) * BATCH_SIZE]\n",
    "#             feed_dict = {story: inst_story, order: inst_order}\n",
    "#             _, current_loss = sess.run([opt_op, loss], feed_dict=feed_dict)\n",
    "#             total_loss += current_loss\n",
    "\n",
    "#         print(' Train loss:', total_loss / n)\n",
    "\n",
    "# #         train_feed_dict = {story: train_stories, order: train_orders}\n",
    "# #         train_predicted = sess.run(predict, feed_dict=train_feed_dict)\n",
    "# #         train_accuracy = nn.calculate_accuracy(train_orders, train_predicted)\n",
    "# #         print(' Train accuracy:', train_accuracy)\n",
    "        \n",
    "#         dev_feed_dict = {story: dev_stories, order: dev_orders}\n",
    "#         dev_predicted = sess.run(predict, feed_dict=dev_feed_dict)\n",
    "#         dev_accuracy = nn.calculate_accuracy(dev_orders, dev_predicted)\n",
    "#         print(' Dev accuracy:', dev_accuracy)\n",
    "\n",
    "        \n",
    "    \n",
    "#     nn.save_model(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 1</font>: Assess Accuracy (40 pts) \n",
    "\n",
    "We assess how well your model performs on an unseen test set. We will look at the accuracy of the predicted sentence order, on sentence level, and will score them as followis:\n",
    "\n",
    "* 0 - 10 pts: 45% <= accuracy < 50%, linear\n",
    "* 10 - 20 pts: 50% <= accuracy < 55, linear\n",
    "* 20 - 40 pts: 55 <= accuracy < 60, linear\n",
    "* extra 0-10 pts: 60 <= accuracy < 70, linear\n",
    "\n",
    "The **linear** mapping maps any accuracy value between the lower and upper bound linearly to a score. For example, if your model's accuracy score is $acc=54.5\\%$, then your score is $10 + 10\\frac{acc-50}{55-50}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Change the following lines so that they construct the test set in the same way you constructed the dev set in the code above. We will insert the test set instead of the dev set here. **`test_feed_dict` variable must stay named the same**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:05:54.755730",
     "start_time": "2016-12-20T12:05:54.617471"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sent len is:  21\n"
     ]
    }
   ],
   "source": [
    "# LOAD THE DATA\n",
    "data_test = nn.load_corpus(data_path + \"dev.tsv\")\n",
    "# make sure you process this with the same pipeline as you processed your dev set\n",
    "test_stories, test_orders, _ = pipeline(data_test, vocab=vocab, max_sent_len_=max_sent_len)\n",
    "f\n",
    "# THIS VARIABLE MUST BE NAMED `test_feed_dict`\n",
    "test_feed_dict = {story: test_stories, order: test_orders}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loads your model, computes accuracy, and exports the result. **DO NOT** change this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:05:55.116609",
     "start_time": "2016-12-20T12:05:54.758571"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56098343132014961"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! ASSESSMENT 1 - DO NOT CHANGE, MOVE NOR COPY\n",
    "with tf.Session() as sess:\n",
    "    # LOAD THE MODEL\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './model/model.checkpoint')\n",
    "    \n",
    "    # RUN TEST SET EVALUATION\n",
    "    dev_predicted = sess.run(predict, feed_dict=test_feed_dict)\n",
    "    dev_accuracy = nn.calculate_accuracy(dev_orders, dev_predicted)\n",
    "\n",
    "dev_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Mark</font>:  Your solution to Task 1 is marked with ** __ points**. \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 2</font>: Describe your Approach\n",
    "\n",
    "Enter a 1000 words max description of your approach **in this cell**.\n",
    "Make sure to provide:\n",
    "- an **error analysis** of the types of errors your system makes\n",
    "- compare your system with the model we provide, focus on differences and draw useful comparations between them\n",
    "\n",
    "Should you need to include figures in your report, make sure they are Python-generated (matplotlib, seaborn, bokeh are all included in the stat-nlp-book Docker image). For that, feel free to create new cells after this cell (before Assessment 2 cell). Link online images at your risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Error Analysis:\n",
    "\n",
    "### Limitation of Our LSTM Model\n",
    "In the current model we are using 4 layers of LSTM followed by a dense layer with a softmax function to predict the order number of the sentence. The problem with this method is that each sentence is handled independently and has to be given an order number (0,1,2,3,4).  Therefore, the other sentences in that same story are not considered during the classification problem and top accuracies won’t be achieved via this method since when predicting a story, all the other sentences in that story also has to be taken into account inside the model.\n",
    "\n",
    "### Possible Better Model\n",
    "A better way is to use a seq2seq model to fix this issue. Where the 5 sentences are passed into an RNN encoder to represent it as a context vector. Each sentence has a \"START\" and \"STOP\" token tag added to the beggining and ending of it respectively. We then use another RNN decoder to decode this context vector into an ouput sequence (order).\n",
    "\n",
    "\n",
    "### Cases of Low Accurancy\n",
    "When looking at the order of the sentences predicted for a story, we realized that there were two majority cases where incorrect orders were predicted for a story:\n",
    "\n",
    "##### 1) OOV\n",
    "In the cases were there were a lot of OOV tokens (words that we did not have an embedding for), the model could not predict the order of the sentences very well. We noticed that many of these tokens were either rare vocabulary words used or person names. In general one could replace these names or websites with \"NAME\" tags and then assign a vector representation for the tags rather than for each individual names. For the rare vocabulary words, a simple way is to extend our word embedding to contain more words.\n",
    "\n",
    "##### 2) PAD\n",
    "For sentences which involved a lot of \"PADDING\" tags at the end of it, the model was also very likely to predict the wrong sequence of orders for the story sentences. One solution to this is to use bucketing to group sentences of different lengths together. When we implemented the seq2seq model using Keras to get the 58% dev set accuracy, this wasn’t a problem because only the end of the story (5 sentences) were \"PADDED\" and not each individual sentence. Unfortunately, the seq2seq model was implemented using an add-on to keras and we couldn't make the pure tensorflow implementation working.\n",
    "\n",
    "##### 3) Mis-spelling\n",
    "Another minor issue for the existance of OOV tokens was that a lot of training words/tokens had spelling mistakes (like \"saddly”, “sandwhich”, “neiter”). Since these words don’t exist in the GloVe word embeddings, they will get the embedding of the “OOV” token. If a script was ran during pre-processing to spell-check and correct these tokens, better results might have been achieved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f8939dcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt;from matplotlib.ticker import MaxNLocator;from collections import namedtuple;n_groups = 5;means_men = (220, 340, 604, 247, 65);fig, ax = plt.subplots();index = np.arange(n_groups);bar_width = 0.35;opacity = 0.4;error_config = {'ecolor': '0.3'};rects1 = ax.bar(index, means_men, bar_width,alpha=opacity, color='b', error_kw=error_config,label='dev');ax.set_xlabel('order label');ax.set_ylabel('Scores');ax.set_title('number of data sample');ax.set_xticks(index + bar_width / 2);ax.set_xticklabels(('0', '1', '2', '3', '4'));ax.legend();fig.tight_layout();plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure shows which the wrong prediction the model makes for each of the order label. As we can see, the \"2\" label gets the worest result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiQ1yYCSJDXp/wMJ4BDnSL4EDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f862b0e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt;from matplotlib.ticker import MaxNLocator;from collections import namedtuple;n_groups = 5;means_men = (2041, 2299, 1131, 1858, 2026);fig, ax = plt.subplots();index = np.arange(n_groups);bar_width = 0.35;opacity = 0.4;error_config = {'ecolor': '0.3'};rects1 = ax.bar(index, means_men, bar_width,alpha=opacity, color='b', error_kw=error_config,label='dev');ax.set_xlabel('order label');ax.set_ylabel('Scores');ax.set_title('number of data sample');ax.set_xticks(index + bar_width / 2);ax.set_xticklabels(('0', '1', '2', '3', '4'));ax.legend();fig.tight_layout();plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure shows how many predictions the model makes for each order label. As it shows, the result corresponds to the previous figure, the model is not confident in making prediction on label \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Explanation:\n",
    "\n",
    "Improvement We Made Based on the Provided Model\n",
    "\n",
    "### Pre-processing\n",
    "\n",
    "* Tokenization\n",
    "\n",
    "The tokenization provided in the original code only split by white spaces “ “. But that is not a good tokenization because for example “the.” and “the” are considered different tokens because of the period sign.\n",
    "We created our tokenization method based on the \n",
    "    - twitter tree bank tokenizer. \n",
    "We added:\n",
    "    - Time \n",
    "    - Data\n",
    "    - Garbled text (\\x1a) \n",
    "    - URL \n",
    "\n",
    "*  Word Embeddings\n",
    "\n",
    "For the story ordering problem, we need word embeddings as input to our model. This can either be pre-trained like GloVe or Word2Vec embeddings or can be trained using unsupervised learning using the training stories we have (their texts). However in the provided model, neither is done. A word embedding matrix is randomly intitialized with values which is inherently non-sense if used within a model.\n",
    "\n",
    "We took 1.6B 300-D word embeddings from GloVe and only included the words which appeared in the training set. We also added two word embeddings:\n",
    "    - <PAD> was a 300D all 0 vectors\n",
    "    - <OOV> was a randomly initialized vector. \n",
    "The 1.6 Billion word 300-D word embeddings was narrowed down to only contain words in the training set. (This was ran on AWS due to the large size of the file)\n",
    "\n",
    "### Model\n",
    "\n",
    "* Model Composition\n",
    "\n",
    "    In the original codes, there's only one dense layer, and the model takes the sum of sentence vector to learning the pattern. This model does not ultilize the features of sentences and words, so it gives low accurance. By analyzing the characteriscts of this story ordering task, we decided to apply rnn and lstm on the sentences to learning their patterns. We feed sentences to the static_rnn with lstm cells, and pass the result to the dense layer for the final classification process. Here's our detailed implementation:\n",
    "\n",
    "    - LSTM: tensorflow BasicLSTM Cell\n",
    "    - Stacked StaticRNN with 4 LSTM Cells \n",
    "    - Fully-Connected Layer\n",
    "      A Fully-connected layer is added to the network to give the output result.\n",
    "    - Dropout layer added to the fully-connected layer, which can prevent the model from overfitting\n",
    "\n",
    "\n",
    "* Optimizer\n",
    "\n",
    "    In the original model, Adam Optimizer is applied, althought Adam is well-known to be the best optimizer, we tested AdadetaOptimizer to see if there's any difference.    \n",
    "    - AdamOptimizer with learning rate 0.01: \n",
    "        low train loss, converge quickly, easy to overfit\n",
    "    - AdadeltaOptimizer with learning rate 0.1: \n",
    "        high train loss, coverge slowly, not easy to overfit  \n",
    "        - The difference of the dev accuracy and training loss is illustrated in the line chart below\n",
    "   \n",
    "    \n",
    "* Regularization\n",
    "\n",
    "    We tried various regularization techniques such as recurrent dropout in the lstm layers and L2 regularizers in the word embeddings. The L2 regularizers performed better. Regularization is used to avoid overfitting and to make sure that the model generalizes on unseen data. Grid hyper-parameter search was then used to pick the best Beta value for the L2 regularizer for the embedding weights. \n",
    "    \n",
    "    - Adopted: L2 regularization is applied on the loss with beta value 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f861deeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as mpatches;orange_patch = mpatches.Patch(color='C1', label='Adadelta Dev');green_patch = mpatches.Patch(color='C2', label='Adam Dev');plt.plot([1, 2, 3, 4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], [0.398,0.433,0.452,0.462,0.473,0.487,0.493,0.502,0.514,0.524,0.529,0.532,0.5356,0.5378,0.5402,  0.5463, 0.548, 0.5493,0.5509,0.5493],\"C1\",label=\"Adadelta Dev\");plt.plot([1, 2, 3, 4,5,6,7,8,9,10],[0.510, 0.527, 0.536,0.539,0.542,0.543,0.549,0.546,0.544,0.542], \"C2\",label=\"Adam Dev\");plt.ylabel('Accuracy');plt.xlabel('Training Epoch');purple_patch = mpatches.Patch(color='C4', label='Adam Train');red_patch = mpatches.Patch(color='C3', label='Adadelta Train');plt.legend(handles=[green_patch, red_patch]);plt.plot([1, 2, 3, 4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], [0.45,0.50,0.51,0.529,0.535,0.543,0.550,0.557,0.562,0.565,0.570,0.573,0.576,0.580,0.583,0.587,0.592 , 0.598,0.60,0.61],\"C3\",label=\"Adadelta Train\");plt.plot([1, 2, 3, 4,5,6,7,8,9,10],[0.572, 0.601, 0.61,0.62,0.63,0.65,0.67,0.675,0.682,0.69], \"C4\",label=\"Adam Train\");plt.legend(handles=[green_patch, red_patch,purple_patch, orange_patch]);plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f8621c5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "red_patch = mpatches.Patch(color='C1', label='Adadelta');green_patch = mpatches.Patch(color='C2', label='Adam');plt.legend(handles=[green_patch, red_patch]);plt.plot([1, 2, 3, 4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], [40,37,36,35,34,33,32,31,30,29.5,28.9,27.8,24.5,23.9,22.5,22.3, 22.1, 21.9,21.12,21.23],\"C1\",label=\"Adadelta\");plt.plot([1, 2, 3, 4,5,6,7,8,9,10],[20, 11.9, 10.2,5.9,5.8,5.75,5.72,5.69,5.54,5.64], \"C2\",label=\"Adam\");plt.ylabel('Training Loss');plt.xlabel('Training Epoch');plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     \n",
    "### Training\n",
    "\n",
    "* Early Stopping\n",
    "\n",
    "Early stopping was implemented to select and save the best model during training which gave the best dev set accuracy. This fixes the problem of having to play around with the number of epochs as a hyperparamter and saves alot of time.\n",
    "\n",
    "* Shuffle Batching\n",
    "\n",
    "We applied tensorflow shuffle batching in the pipeline in order to get more randomized data sample from the data set. \n",
    "\n",
    "* Hyper-parameter Tuning\n",
    "\n",
    "    - Optimizer Learning rate:\n",
    "     <table>\n",
    "        <tr> \n",
    "            <th>Optimizer learning rate</th>\n",
    "            <th> Highest score </th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td> 0.1</td>\n",
    "            <td>55.4</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td> 0.01</td>\n",
    "            <td>56.0</td>\n",
    "        </tr>\n",
    "           <tr>\n",
    "            <td> 0.001</td>\n",
    "            <td>54.4</td>\n",
    "        </tr>\n",
    "        </table>\n",
    "    - Regularization rate: \n",
    "    <table>\n",
    "    <tr> \n",
    "        <th>L2 rate</th>\n",
    "        <th> Highest score </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 0.1</td>\n",
    "        <td>56.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 0.01</td>\n",
    "        <td>55.4</td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "        <td> 0.001</td>\n",
    "        <td>54.9</td>\n",
    "    </tr>\n",
    "    </table>\n",
    "    \n",
    "    - Batch size:\n",
    "      we tried 32, 64, 128, 256, 512 for batch size, and we got the results showing that smaller batch size gave higher train loss, while larger batch size gave smaller train loss. With batch size 256, we can get the best result. \n",
    "       <table>\n",
    "    <tr> \n",
    "        <th> Batch size</th>\n",
    "        <th> Highest score </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 64</td>\n",
    "        <td>53.9</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 128</td>\n",
    "        <td>55.4</td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "        <td> 256</td>\n",
    "        <td>56.1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 512</td>\n",
    "        <td>54.1</td>\n",
    "    </tr>\n",
    "    </table>\n",
    "    \n",
    "      \n",
    "### Other Attempts We Made\n",
    "\n",
    "* Word to Vector Model\n",
    "\n",
    "    * Bi-directional rnn\n",
    "    \n",
    "    We got 54.2 with bidirectional rnn. The possible reason is that we added padding to each of sentences, so that the forward and backward learning cannot improve the performance.\n",
    "\n",
    "    * Dynamic rnn \n",
    "    \n",
    "    Rather than padding the sentences to be the same length, we applied dynamic rnn to the sentences, but we got similiar result, 54.6. Considering the training time(dynamic rnn will locate memory each time, which is much slower than static rnn), we chose static rnn as our final model.\n",
    "\n",
    "\n",
    "* Sentence to Vector Model\n",
    "\n",
    "    Based on the sent2vec idea, we applied static rnn and bi directional rnn to each of the stories, but the highest score we got is 53.5.  \n",
    "\n",
    "    * static rnn \n",
    "    \n",
    "    * Bi-directional rnn\n",
    "\n",
    "\n",
    "* Ensemble Learning\n",
    "\n",
    "    We have implemented Sent2Vec model and Word2Vec model, and some of the predicted results differs in the two model, so that we tried to apply the idea of ensemble learning on these two models -- Besides the results that are identical in these two models, choose the result that have higher probability among the two results set, and add to the final result set. \n",
    "    \n",
    "    The final result we get is <strong> 56.1 </strong>, but the model size exceed the size limit. \n",
    "\n",
    "\n",
    "Finally, here's a table showing all the methods we tried and all the highest score we got.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th> Model </th>\n",
    "        <th> Hyper-parameters <th>\n",
    "        <th> Highest Score </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Static RNN + LSTM(4) </td>\n",
    "        <td> batch size: 256; learning rate: 0.1; </td>\n",
    "        <td> 56.1 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Bi-directional RNN + LSTM(2) </td>\n",
    "        <td> batch size: 256; learning rate: 0.01; </td>\n",
    "        <td> 54. </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Dynamic RNN + LSTM(2) </td>\n",
    "        <td> batch size: 256; learning rate: 0.01; </td>\n",
    "        <td> 54.6 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Sent2Vec RNN </td>\n",
    "        <td> batch size: 256; learning rate: 0.01; </td>\n",
    "        <td> 53.5 </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 2</font>: Assess Description (60 pts) \n",
    "\n",
    "We will mark the description along the following dimensions: \n",
    "\n",
    "* Clarity (10pts: very clear, 0pts: we can't figure out what you did, or you did nothing)\n",
    "* Creativity (25pts: we could not have come up with this, 0pts: Use only the provided model)\n",
    "* Substance (25pts: implemented complex state-of-the-art classifier, compared it to a simpler model, 0pts: Only use what is already there)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Mark</font>:  Your solution to Task 2 is marked with ** __ points**.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Final mark</font>: Your solution to Assignment 3 is marked with ** __points**. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
